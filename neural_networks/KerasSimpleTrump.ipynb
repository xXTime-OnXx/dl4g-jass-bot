{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for a simple neural network\n",
    "\n",
    "## Trump by maximum color (2 colors)\n",
    "\n",
    "The inputs to the network are the number of cards of each color. The network should learn to select the color with the largest number of cards of that color.\n",
    "\n",
    "For a simple example, let us assume that there are 5 cards in total for a player and only 2 colors.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "We use the keras library for building, training and evaluating the network. A tutorial for keras can be found on (https://keras.io/) or https://www.tensorflow.org/guide/keras. There are different implementations of keras, here I will use the one build on tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function\n",
    "\n",
    "We have to encode the output somehow, for two classes, the simplest solution is a single variable that should be 0 if there are more cards of color 0 and 1 if there are more cards of color 1.\n",
    "\n",
    "### Training and label data.\n",
    "\n",
    "So we can prepare some training data. In this simple case, all the possible configurations are actually known.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 5.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [3. 2.]\n",
      " [4. 1.]\n",
      " [5. 0.]]\n",
      "[1. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([\n",
    "    [0, 5],\n",
    "    [1, 4],\n",
    "    [2, 3],\n",
    "    [3, 2],\n",
    "    [4, 1],\n",
    "    [5, 0],\n",
    "], dtype=np.float32)\n",
    "y_train = np.array([1, 1, 1, 0, 0, 0,], dtype=np.float32)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Input data can have different ranges. It is always a good idea (in other words absolutely essential) to normalize the input data. This is usually done into the range 0..1 or -1..1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1. ]\n",
      " [0.2 0.8]\n",
      " [0.4 0.6]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train / 5.0\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first network.\n",
    "\n",
    "We will start with a very simple network, where we connect the inputs directly to the output. So there will be 2 variables, the weights for the connection and the bias. The output function is a sigmoid, which takes values between 0 and 1.\n",
    "\n",
    "With keras, we first have to create the type of model we want (Sequential), and can then add layers. In the tensorflow implementation, we have to add the input_shape parameter in the first layer to tell it the format of the input. This does not include the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/.pyenv/versions/dl4g/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', input_shape=[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to compile the model and tell it what loss function and optimizer we want to have. We will take a mean squared error for loss function first. (This is actually not optimal and will be corrected in an exercise).\n",
    "\n",
    "Besides the loss, we usually want to look at some metrics. Here we choose accuracy, that measures how often the network makes the correct decision (see last lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print some details about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.0780274],\n",
      "       [-1.071946 ]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either train one batch, or we can use fit to train repeatedly. The result from the training is the loss function and the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.30994585, dtype=float32), array(0.5, dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to fit the data in minibatches multiple times. This will calculate the weights, so as to minimize the loss. We might not always get a good result in the first try and even this very simple network seems to need a large number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.3098\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.3096\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3094\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3092\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3090\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3088\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3086\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.3084\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.3082\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3080\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.3078\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3076\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 0.3074\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5000 - loss: 0.3072\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3070\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3068\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3066\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3064\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3062\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3060\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3058\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3056\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3054\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3052\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3050\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3048\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3046\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3045\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3043\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3041\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3039\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3037\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3035\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3033\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3031\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3029\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3027\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3025\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3023\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5000 - loss: 0.3021\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3019\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3017\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3015\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3013\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3011\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3009\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.3007\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3005\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3003\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.3001\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.2999\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2997\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2995\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2993\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2991\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2989\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2987\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2985\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2983\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2981\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2979\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2977\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2975\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5000 - loss: 0.2973\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2971\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2969\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2967\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2965\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2964\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2962\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2960\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2958\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2956\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2954\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2952\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2950\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2948\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2946\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2944\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2942\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2940\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2938\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2936\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2934\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2932\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2930\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2928\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.2926\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2924\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2922\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2920\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2918\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2916\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2914\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2912\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.2910\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2908\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 0.2906\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2904\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13589cc70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the values from the training value. Why are the results floating point number and not 0 or 1? Does the result seem likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29474062],\n",
       "       [0.28959766],\n",
       "       [0.2845082 ],\n",
       "       [0.2794731 ],\n",
       "       [0.27449283],\n",
       "       [0.26956815]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the found weights for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "[array([[-1.0903776 ],\n",
      "       [-0.96603286]], dtype=float32), array([0.09356276], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the actual predictions? We use a threshold on the output of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A larger network\n",
    "\n",
    "Lets try a more complicated network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5000 - loss: 0.2547\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2546\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2544\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2542\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2541\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2539\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2537\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2536\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2534\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2532\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2531\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2529\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5000 - loss: 0.2527\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2525\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2524\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2522\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2520\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2519\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2517\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2515\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2513\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2512\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2510\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2508\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2507\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2505\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2503\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2502\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2500\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2498\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2496\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2495\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2493\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2491\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2489\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2488\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2486\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2484\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.2483\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2481\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2479\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2477\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2476\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2474\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2472\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2470\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2469\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2467\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2465\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2464\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2462\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2460\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2458\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2457\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2455\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2453\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2452\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2450\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2448\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2447\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2445\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2443\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2441\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2440\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2438\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2436\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2435\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2433\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2431\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2430\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2428\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2426\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2425\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2423\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2421\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2420\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2418\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2416\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2415\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2413\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2411\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2410\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2408\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2406\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2404\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2403\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2401\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2399\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5000 - loss: 0.2398\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2396\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2394\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2393\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2391\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2390\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2388\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2386\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2385\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2383\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2381\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2380\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2378\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2376\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2375\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2373\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2371\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2370\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2368\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2366\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2365\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2363\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2361\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2360\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2358\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2356\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2355\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2353\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2352\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2350\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2348\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2347\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2345\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2343\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2342\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2340\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2338\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2337\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2335\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2333\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2332\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2330\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2329\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2327\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2325\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2324\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2322\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2320\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2319\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2317\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2315\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2314\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2312\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2311\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2309\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2307\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2306\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2304\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2302\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2301\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2299\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2298\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2296\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2294\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2293\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2291\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.2289\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2288\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2286\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2285\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2283\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2282\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2281\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2280\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2278\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2277\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2276\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2275\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2274\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2272\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2271\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2270\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2269\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2268\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5000 - loss: 0.2266\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2265\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2264\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5000 - loss: 0.2263\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2262\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2260\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2259\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2258\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5000 - loss: 0.2257\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2256\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2255\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 0.2253\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2252\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2251\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2250\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2249\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2248\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2246\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2245\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2244\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2243\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2242\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2241\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2239\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2238\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.2237\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 0.2236\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - loss: 0.2235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x135c7e230>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not necessarly better, how does the prediction look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48882976],\n",
       "       [0.4961097 ],\n",
       "       [0.47197187],\n",
       "       [0.4011635 ],\n",
       "       [0.42966792],\n",
       "       [0.44795236]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dense name=dense_1, built=True>\n",
      "[array([[-0.6104649 , -0.11350176],\n",
      "       [ 0.73114324,  0.9613214 ]], dtype=float32), array([0.07478556, 0.03273025], dtype=float32)]\n",
      "<Dense name=dense_2, built=True>\n",
      "[array([[ 0.7776954 , -1.18779   ],\n",
      "       [-0.01529608,  0.4107743 ]], dtype=float32), array([-0.04563887,  0.18150689], dtype=float32)]\n",
      "<Dense name=dense_3, built=True>\n",
      "[array([[-0.14181603],\n",
      "       [-1.3471451 ]], dtype=float32), array([0.03556861], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer)\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger network, does not seem to work better as the simpler one. Or is it maybe not large enough?\n",
    "\n",
    "The problem is not the network, but the data, we just do not have enough data. So lets try to make up some more data artificially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.random.random(size=(10000,2))\n",
    "y_new = np.zeros(10000, dtype=np.float32)\n",
    "condition = (x_new[:,1] > x_new[:,0])\n",
    "y_new[condition] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6146 - loss: 0.2236\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7848 - loss: 0.2157\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8202 - loss: 0.2104\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.8368 - loss: 0.2035\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8520 - loss: 0.1979\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.8642 - loss: 0.1905\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8810 - loss: 0.1840\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8947 - loss: 0.1777\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9071 - loss: 0.1704\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9251 - loss: 0.1647\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9272 - loss: 0.1580\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9422 - loss: 0.1509\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9476 - loss: 0.1424\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.9591 - loss: 0.1354\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.9633 - loss: 0.1294\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9725 - loss: 0.1218\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.9729 - loss: 0.1156\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9766 - loss: 0.1090\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9811 - loss: 0.1041\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9841 - loss: 0.0976\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9875 - loss: 0.0920\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9912 - loss: 0.0873\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9906 - loss: 0.0835\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9946 - loss: 0.0790\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.9927 - loss: 0.0763\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9936 - loss: 0.0721\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9927 - loss: 0.0693\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9952 - loss: 0.0657\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9962 - loss: 0.0621\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9951 - loss: 0.0606\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9964 - loss: 0.0582\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9970 - loss: 0.0559\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9964 - loss: 0.0528\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.9980 - loss: 0.0526\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9978 - loss: 0.0511\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9986 - loss: 0.0487\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9970 - loss: 0.0471\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9983 - loss: 0.0467\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9979 - loss: 0.0461\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9957 - loss: 0.0445\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9981 - loss: 0.0424\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9990 - loss: 0.0416\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9984 - loss: 0.0411\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9980 - loss: 0.0393\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9988 - loss: 0.0387\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9982 - loss: 0.0385\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.9976 - loss: 0.0374\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.9977 - loss: 0.0364\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9975 - loss: 0.0357\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9960 - loss: 0.0354\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9984 - loss: 0.0349\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9980 - loss: 0.0346\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9979 - loss: 0.0333\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9967 - loss: 0.0325\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.9979 - loss: 0.0334\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.9980 - loss: 0.0330\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9984 - loss: 0.0309\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9978 - loss: 0.0312\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9976 - loss: 0.0306\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9984 - loss: 0.0296\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9974 - loss: 0.0304\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9979 - loss: 0.0296\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9977 - loss: 0.0282\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9979 - loss: 0.0285\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9970 - loss: 0.0293\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.9981 - loss: 0.0279\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9978 - loss: 0.0281\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9975 - loss: 0.0278\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9983 - loss: 0.0268\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9974 - loss: 0.0268\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.9974 - loss: 0.0264\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9981 - loss: 0.0255\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9978 - loss: 0.0264\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9977 - loss: 0.0253\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.9985 - loss: 0.0260\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.9978 - loss: 0.0251\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9970 - loss: 0.0252\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9981 - loss: 0.0250\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9979 - loss: 0.0240\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.9985 - loss: 0.0238\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9974 - loss: 0.0240\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9974 - loss: 0.0226\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9963 - loss: 0.0225\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.9978 - loss: 0.0230\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9986 - loss: 0.0225\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.9982 - loss: 0.0224\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.9974 - loss: 0.0224\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9982 - loss: 0.0224\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.9973 - loss: 0.0229\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9986 - loss: 0.0224\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9980 - loss: 0.0226\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.9984 - loss: 0.0216\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.9981 - loss: 0.0216\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.9983 - loss: 0.0214\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.9981 - loss: 0.0211\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.9984 - loss: 0.0200\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9985 - loss: 0.0208\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.9972 - loss: 0.0204\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.9983 - loss: 0.0205\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9976 - loss: 0.0195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1361538e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_new, y_new, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems better. Lets look how it performs on our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9986818 ],\n",
       "       [0.99251163],\n",
       "       [0.95865595],\n",
       "       [0.02679891],\n",
       "       [0.01845099],\n",
       "       [0.02047551]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We might want to check how the network performs on any data. For this, keras provides the evaluate function that will \n",
    "evaluate the loss and the metrics. So of course label (y) data is needed for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.9978 - loss: 0.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02013344131410122, 0.9984999895095825]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we would normally do that on validation or test data not used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.9976 - loss: 0.0219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020534705370664597, 0.9983999729156494]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_new = np.random.random(size=(5000,2))\n",
    "y_val_new = np.zeros(5000, dtype=np.float32)\n",
    "y_val_new[x_val_new[:,1] > x_val_new[:,0]] = 1.0\n",
    "model.evaluate(x_val_new, y_val_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "It is essential to visualise the training process to see what is going on. In Keras, an easy method to do this is to use the history object that is returned from fit. It contains the metrics and the loss.\n",
    "\n",
    "We will also split our data into training and validation for this test. We rebuild the model, so that it is initialized again. Otherwise we would just continue with the weights from the previous fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5038 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 2/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.5070 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.5126 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 4/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.5120 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 5/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5185 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 6/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.4998 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 7/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5027 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 8/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.5113 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 9/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.5028 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 10/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5104 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 11/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.5186 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 12/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5031 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 13/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.5122 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 14/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.5035 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 15/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.4934 - loss: 0.2501 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 16/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.5057 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 17/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.5014 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 18/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.5133 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 19/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.5007 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 20/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.5023 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 21/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5187 - loss: 0.2498 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 22/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5099 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 23/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5028 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 24/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.5073 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 25/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.5076 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 26/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.5025 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 27/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.5010 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 28/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.5008 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 29/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.5036 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 30/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5154 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 31/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.4935 - loss: 0.2501 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 32/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5126 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 33/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.5060 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 34/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.4996 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 35/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.5045 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 36/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.5117 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 37/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.5048 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 38/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5080 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 39/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.4961 - loss: 0.2501 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 40/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.5090 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 41/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.5104 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 42/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.5089 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 43/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.5064 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 44/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.5028 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 45/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5054 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 46/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.5150 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 47/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.5060 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 48/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.5029 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 49/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.5120 - loss: 0.2499 - val_accuracy: 0.5052 - val_loss: 0.2500\n",
      "Epoch 50/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.5054 - loss: 0.2500 - val_accuracy: 0.5052 - val_loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13708e6e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1373e15d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Correct loss function\n",
    "\n",
    "The loss function used above (mse) is not optimal. A better loss function would be the crossentropy. Change the network to use that loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0620 - loss: 0.7055 - val_accuracy: 0.1512 - val_loss: 0.7018\n",
      "Epoch 2/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.1845 - loss: 0.7012 - val_accuracy: 0.2800 - val_loss: 0.6989\n",
      "Epoch 3/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.3159 - loss: 0.6983 - val_accuracy: 0.3616 - val_loss: 0.6972\n",
      "Epoch 4/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.3827 - loss: 0.6970 - val_accuracy: 0.4212 - val_loss: 0.6962\n",
      "Epoch 5/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.4191 - loss: 0.6960 - val_accuracy: 0.4564 - val_loss: 0.6955\n",
      "Epoch 6/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.4694 - loss: 0.6952 - val_accuracy: 0.4836 - val_loss: 0.6950\n",
      "Epoch 7/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.4892 - loss: 0.6949 - val_accuracy: 0.4948 - val_loss: 0.6946\n",
      "Epoch 8/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.4777 - loss: 0.6948 - val_accuracy: 0.5044 - val_loss: 0.6943\n",
      "Epoch 9/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.5139 - loss: 0.6940 - val_accuracy: 0.5052 - val_loss: 0.6941\n",
      "Epoch 10/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.4924 - loss: 0.6944 - val_accuracy: 0.5052 - val_loss: 0.6939\n",
      "Epoch 11/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.5106 - loss: 0.6938 - val_accuracy: 0.5052 - val_loss: 0.6938\n",
      "Epoch 12/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.5141 - loss: 0.6936 - val_accuracy: 0.5052 - val_loss: 0.6937\n",
      "Epoch 13/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5116 - loss: 0.6935 - val_accuracy: 0.5052 - val_loss: 0.6936\n",
      "Epoch 14/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.5006 - loss: 0.6937 - val_accuracy: 0.5052 - val_loss: 0.6936\n",
      "Epoch 15/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.4988 - loss: 0.6937 - val_accuracy: 0.5052 - val_loss: 0.6935\n",
      "Epoch 16/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.5088 - loss: 0.6934 - val_accuracy: 0.5052 - val_loss: 0.6935\n",
      "Epoch 17/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5077 - loss: 0.6934 - val_accuracy: 0.5052 - val_loss: 0.6934\n",
      "Epoch 18/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.5077 - loss: 0.6934 - val_accuracy: 0.5052 - val_loss: 0.6934\n",
      "Epoch 19/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5071 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 20/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.4996 - loss: 0.6935 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 21/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.5099 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 22/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.5011 - loss: 0.6934 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 23/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.4985 - loss: 0.6935 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 24/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5058 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6933\n",
      "Epoch 25/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.4941 - loss: 0.6935 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 26/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.5152 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 27/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.5131 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 28/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5021 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 29/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.5058 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 30/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.5040 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 31/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5020 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 32/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.5150 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 33/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5081 - loss: 0.6931 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 34/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.5043 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 35/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5035 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 36/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.5090 - loss: 0.6931 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 37/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.5024 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 38/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.5106 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6932\n",
      "Epoch 39/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5083 - loss: 0.6931 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 40/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.5055 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 41/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.5049 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 42/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.5118 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 43/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.5022 - loss: 0.6932 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 44/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.5135 - loss: 0.6929 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 45/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5128 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 46/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.4993 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 47/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.4966 - loss: 0.6934 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 48/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.5010 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 49/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.5006 - loss: 0.6933 - val_accuracy: 0.5052 - val_loss: 0.6931\n",
      "Epoch 50/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5111 - loss: 0.6930 - val_accuracy: 0.5052 - val_loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Maximum of 4 colors\n",
    "\n",
    "Implement a network that will receive 4 colors and has to select one of them.\n",
    "\n",
    "This will require a change of the labels (y) that now take values of 0, 1, 2 or 3. However, networks do not use labels in that form directly for multi class classification, but use 1-hot encoded or categorical data instead.\n",
    "\n",
    "In keras there is a function `keras.utils.to_categorical` that can be used for that.\n",
    "\n",
    "The last layer in the network should then no longer be sigmoid, but the softmax function. And we need the multiclass form of the crossentropy function, which in keras is called `categorical_crossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.2938 - loss: 1.3560\n",
      "Epoch 2/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7059 - loss: 1.2109\n",
      "Epoch 3/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7578 - loss: 1.0266\n",
      "Epoch 4/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7919 - loss: 0.8359\n",
      "Epoch 5/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.8271 - loss: 0.6752\n",
      "Epoch 6/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.8602 - loss: 0.5648\n",
      "Epoch 7/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.8975 - loss: 0.4756\n",
      "Epoch 8/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.9180 - loss: 0.4241\n",
      "Epoch 9/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.9329 - loss: 0.3681\n",
      "Epoch 10/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.9446 - loss: 0.3282\n",
      "Epoch 11/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.9460 - loss: 0.3055\n",
      "Epoch 12/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.9453 - loss: 0.2746\n",
      "Epoch 13/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.9576 - loss: 0.2481\n",
      "Epoch 14/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.9614 - loss: 0.2388\n",
      "Epoch 15/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.9603 - loss: 0.2209\n",
      "Epoch 16/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.9584 - loss: 0.2113\n",
      "Epoch 17/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.9615 - loss: 0.1993\n",
      "Epoch 18/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9673 - loss: 0.1850\n",
      "Epoch 19/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.9651 - loss: 0.1761\n",
      "Epoch 20/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.9691 - loss: 0.1736\n"
     ]
    }
   ],
   "source": [
    "x_train= np.random.random(size=(5000,4))\n",
    "y_train_label = np.argmax(x_train, axis=1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_label, num_classes=4)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid')) # match the target variables (one neuron per category)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # Multiclass classification loss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.1409\n",
      "Test Loss: 0.1409, Test Accuracy: 1.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predictions: [2 0 0 2 1 3 0 2 3 3]\n",
      "True Labels: [2 0 0 2 1 3 0 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model with a sample input\n",
    "x_test = np.random.random(size=(10, 4))\n",
    "y_test_label = np.argmax(x_test, axis=1)\n",
    "y_test = keras.utils.to_categorical(y_test_label, num_classes=4)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(x_test)\n",
    "print(\"Predictions:\", np.argmax(predictions, axis=1))\n",
    "print(\"True Labels:\", y_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implement a ML Network to learn trump from features\n",
    "\n",
    "We would like to train a network to **get the trump** from some features. (We could use the cards directly, but this is deep learning and we will see more of that in next lesson :-) )\n",
    "\n",
    "As features we can use the **number of cards of a color** as before and some of the features from last lecture. For keras all input features should be floating point numbers. Also we need numpy arrays and not pandas. To get the array from a panda, the property `values` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  CK  CQ  CJ  C10  C9  C8  C7  \\\n",
       "0   0   0   0   1    1   0   1   1   0   0  ...   0   1   0    0   0   1   0   \n",
       "1   0   0   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   1   \n",
       "2   1   0   0   1    0   0   0   0   0   0  ...   0   1   0    0   0   0   1   \n",
       "3   0   0   0   0    0   0   0   0   0   1  ...   0   0   0    1   1   0   0   \n",
       "4   0   1   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   0   \n",
       "\n",
       "   C6  FH  trump  \n",
       "0   0   0      6  \n",
       "1   0   0      5  \n",
       "2   1   0      6  \n",
       "3   0   0      5  \n",
       "4   0   1      4  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_data = Path('../data')\n",
    "# Import only a fraction of data for efficient testing\n",
    "data = pd.read_csv(path_to_data / '2018_10_18_trump.csv', header=None, nrows=1000)\n",
    "cards = [\n",
    "# Diamonds\n",
    "'DA','DK','DQ','DJ','D10','D9','D8','D7','D6',\n",
    "# Hearts\n",
    "'HA','HK','HQ','HJ','H10','H9','H8','H7','H6',\n",
    "# Spades\n",
    "'SA','SK','SQ','SJ','S10','S9','S8','S7','S6',\n",
    "# Clubs\n",
    "'CA','CK','CQ','CJ','C10','C9','C8','C7','C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "\n",
    "user  = ['user']\n",
    "trump = ['trump']\n",
    "\n",
    "feature_columns = forehand\n",
    "\n",
    "data.columns = cards + forehand + user + trump\n",
    "data.drop('user', axis='columns', inplace=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue as follows:\n",
    "- Calculate features, \n",
    "- add them to the data set\n",
    "- drop the columns not used\n",
    "- convert to numpy array\n",
    "- build a network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  C9  C8  C7  C6  FH  trump  \\\n",
       "0     0   0   0   1    1   0   1   1   0   0  ...   0   1   0   0   0      6   \n",
       "1     0   0   0   0    0   0   0   0   1   1  ...   0   0   1   0   0      5   \n",
       "2     1   0   0   1    0   0   0   0   0   0  ...   0   0   1   1   0      6   \n",
       "3     0   0   0   0    0   0   0   0   0   1  ...   1   0   0   0   0      5   \n",
       "4     0   1   0   0    0   0   0   0   1   1  ...   0   0   0   0   1      4   \n",
       "..   ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..    ...   \n",
       "995   0   0   0   0    0   0   0   1   0   0  ...   0   0   1   1   0      6   \n",
       "996   0   1   0   0    0   1   0   0   1   0  ...   1   0   0   0   0      3   \n",
       "997   1   0   1   1    0   0   0   1   0   0  ...   0   0   1   0   1      4   \n",
       "998   0   0   1   0    1   0   0   0   0   0  ...   1   0   1   0   1      2   \n",
       "999   0   1   0   0    0   0   0   0   0   0  ...   1   0   0   0   0      6   \n",
       "\n",
       "     diamonds_count  hearts_count  spades_count  clubs_count  \n",
       "0                 4             0             3            2  \n",
       "1                 1             4             2            2  \n",
       "2                 2             2             2            3  \n",
       "3                 0             3             3            3  \n",
       "4                 2             5             1            1  \n",
       "..              ...           ...           ...          ...  \n",
       "995               1             2             3            3  \n",
       "996               3             2             1            3  \n",
       "997               4             0             2            3  \n",
       "998               2             1             4            2  \n",
       "999               1             4             2            2  \n",
       "\n",
       "[1000 rows x 42 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diamonds_count'] = data.iloc[:, 0:9].sum(axis=1)\n",
    "feature_columns.append('diamonds_count')\n",
    "\n",
    "data['hearts_count'] = data.iloc[:, 9:18].sum(axis=1)\n",
    "feature_columns.append('hearts_count')\n",
    "\n",
    "data['spades_count'] = data.iloc[:, 18:27].sum(axis=1)\n",
    "feature_columns.append('spades_count')\n",
    "\n",
    "data['clubs_count'] = data.iloc[:, 27:36].sum(axis=1)\n",
    "feature_columns.append('clubs_count')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  spades_count  clubs_count  \\\n",
       "0   0   0   0   1    1   0   1   1   0   0  ...             3            2   \n",
       "1   0   0   0   0    0   0   0   0   1   1  ...             2            2   \n",
       "2   1   0   0   1    0   0   0   0   0   0  ...             2            3   \n",
       "3   0   0   0   0    0   0   0   0   0   1  ...             3            3   \n",
       "4   0   1   0   0    0   0   0   0   1   1  ...             1            1   \n",
       "\n",
       "   D_J9  D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0     0      0     0      0     0      0     0      0  \n",
       "1     0      0     0      0     0      0     0      0  \n",
       "2     0      0     0      0     0      0     0      0  \n",
       "3     0      0     0      0     0      0     0      0  \n",
       "4     0      0     0      1     0      0     0      0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for color in 'DHSC':\n",
    "    \n",
    "    # Jack and nine combination\n",
    "    new_col_J9 = '{}_J9'.format(color)\n",
    "    data[new_col_J9]  = data['{}J'.format(color)] & data['{}9'.format(color)]\n",
    "    feature_columns.append(new_col_J9)\n",
    "    \n",
    "    # Exercise: Add other features here such as the combination of Ace-King-Queen (Dreiblatt).\n",
    "    # Ace-King-Queen (Dreiblatt) combination\n",
    "    new_col_AKQ = '{}_AKQ'.format(color)\n",
    "    data[new_col_AKQ]  = data['{}A'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col_AKQ)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FH  trump  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  \\\n",
       "0   0      6               4             0             3            2     0   \n",
       "1   0      5               1             4             2            2     0   \n",
       "2   0      6               2             2             2            3     0   \n",
       "3   0      5               0             3             3            3     0   \n",
       "4   1      4               2             5             1            1     0   \n",
       "\n",
       "   D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0      0     0      0     0      0     0      0  \n",
       "1      0     0      0     0      0     0      0  \n",
       "2      0     0      0     0      0     0      0  \n",
       "3      0     0      0     0      0     0      0  \n",
       "4      0     0      1     0      0     0      0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(cards, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encode Trump Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PUSH</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>UNE_UFE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>PUSH</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>UNE_UFE</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>OBE_ABE</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FH    trump  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  \\\n",
       "0   0     PUSH               4             0             3            2     0   \n",
       "1   0  UNE_UFE               1             4             2            2     0   \n",
       "2   0     PUSH               2             2             2            3     0   \n",
       "3   0  UNE_UFE               0             3             3            3     0   \n",
       "4   1  OBE_ABE               2             5             1            1     0   \n",
       "\n",
       "   D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0      0     0      0     0      0     0      0  \n",
       "1      0     0      0     0      0     0      0  \n",
       "2      0     0      0     0      0     0      0  \n",
       "3      0     0      0     0      0     0      0  \n",
       "4      0     0      1     0      0     0      0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trump = data.trump.astype('category')\n",
    "data.trump = data.trump.cat.rename_categories({0: 'DIAMONDS', 1: 'HEARTS', 2: 'SPADES', 3:'CLUBS',\n",
    "                                  4: 'OBE_ABE', 5: 'UNE_UFE', 6: 'PUSH', 10: 'PUSH'})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "      <th>trump_DIAMONDS</th>\n",
       "      <th>trump_HEARTS</th>\n",
       "      <th>trump_SPADES</th>\n",
       "      <th>trump_CLUBS</th>\n",
       "      <th>trump_OBE_ABE</th>\n",
       "      <th>trump_UNE_UFE</th>\n",
       "      <th>trump_PUSH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FH  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  D_AKQ  \\\n",
       "0   0               4             0             3            2     0      0   \n",
       "1   0               1             4             2            2     0      0   \n",
       "2   0               2             2             2            3     0      0   \n",
       "3   0               0             3             3            3     0      0   \n",
       "4   1               2             5             1            1     0      0   \n",
       "\n",
       "   H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  trump_DIAMONDS  trump_HEARTS  \\\n",
       "0     0      0     0      0     0      0           False         False   \n",
       "1     0      0     0      0     0      0           False         False   \n",
       "2     0      0     0      0     0      0           False         False   \n",
       "3     0      0     0      0     0      0           False         False   \n",
       "4     0      1     0      0     0      0           False         False   \n",
       "\n",
       "   trump_SPADES  trump_CLUBS  trump_OBE_ABE  trump_UNE_UFE  trump_PUSH  \n",
       "0         False        False          False          False        True  \n",
       "1         False        False          False           True       False  \n",
       "2         False        False          False          False        True  \n",
       "3         False        False          False           True       False  \n",
       "4         False        False           True          False       False  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, ['trump', ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features & Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features (X) and target (y)\n",
    "X = data[feature_columns]\n",
    "y = data[\n",
    "    [\n",
    "        \"trump_DIAMONDS\",\n",
    "        \"trump_HEARTS\",\n",
    "        \"trump_SPADES\",\n",
    "        \"trump_CLUBS\",\n",
    "        \"trump_OBE_ABE\",\n",
    "        \"trump_UNE_UFE\",\n",
    "        \"trump_PUSH\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test sets\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/.pyenv/versions/dl4g/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.3527 - loss: 1.8777 \n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.3850 - loss: 1.7145\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.3984 - loss: 1.6169\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.4213 - loss: 1.5657\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.4718 - loss: 1.5439\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.4954 - loss: 1.4766\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.5408 - loss: 1.3986\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.5515 - loss: 1.3287\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.5226 - loss: 1.3324\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.5344 - loss: 1.3252\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.5491 - loss: 1.2767\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.5587 - loss: 1.2564\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.5648 - loss: 1.2613\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5135 - loss: 1.3003\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.5396 - loss: 1.2578\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.5314 - loss: 1.2455\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.5534 - loss: 1.2167\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.5597 - loss: 1.1972\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.5706 - loss: 1.1914\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.5436 - loss: 1.2190\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.5899 - loss: 1.1490\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.5752 - loss: 1.1943\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.5731 - loss: 1.1783\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.5619 - loss: 1.1795\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.6100 - loss: 1.1183\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.5805 - loss: 1.1102\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.5917 - loss: 1.1409\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.5949 - loss: 1.1289\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.5895 - loss: 1.1063\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.5797 - loss: 1.1693\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.5926 - loss: 1.1042\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.6055 - loss: 1.0997\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.5559 - loss: 1.1680\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.5409 - loss: 1.1649\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.6150 - loss: 1.0798\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.5871 - loss: 1.1421\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.5952 - loss: 1.1540\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.5764 - loss: 1.1384\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.5875 - loss: 1.0925\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.5906 - loss: 1.0982\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.5777 - loss: 1.1353\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.5939 - loss: 1.1295\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.5898 - loss: 1.0951\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.6050 - loss: 1.0896\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.5733 - loss: 1.1383\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.5800 - loss: 1.1073\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6155 - loss: 1.1182\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6088 - loss: 1.0902\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.5880 - loss: 1.1118\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.5902 - loss: 1.1387\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(26, activation='relu', input_shape=(X_train_normalized.shape[1],)))\n",
    "model.add(keras.layers.Dense(26, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='softmax')) # match the target variables (one neuron per category)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # Multiclass classification loss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_normalized, y_train, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5264 - loss: 1.2500\n",
      "Test Loss: 1.2828, Test Accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_normalized, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
